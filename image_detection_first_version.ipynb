{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1NEj4EPrHR3FDQyaNQ9FbeoWu3F7R_Ley",
      "authorship_tag": "ABX9TyP/7w+tNsytTQghS8WfnhKb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ROzenSaglam/Face_detection/blob/main/image_detection_first_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P218xaUvPMJl"
      },
      "outputs": [],
      "source": [
        "!pip install labelme tensorflow opencv-python matplotlib albumentations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Collecting Images\n",
        "\n",
        "import os\n",
        "import time\n",
        "import uuid\n",
        "import cv2\n",
        "\n",
        "print(\"Successfully imported!\")"
      ],
      "metadata": {
        "id": "9p31CHQnPYc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KcdZXsgDwv4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "0lvbsV_cPkEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EBATvU3XPrzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = os.path.join('data','image')\n",
        "number_images = 30"
      ],
      "metadata": {
        "id": "KuFvpPscPyvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8CBTSyg6P6WQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = tf.data.Dataset.list_files('/content/drive/MyDrive/data/image/*.jpg', shuffle = False)"
      ],
      "metadata": {
        "id": "HfSQFcsqQG1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "HzM9p0ZNnVm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to read an image, decode it and reshape the tensor containing the pixel data:\n",
        "\n",
        "def load_image(x):\n",
        "  raw = tf.io.read_file(x)\n",
        "  img = tf.image.decode_jpeg(raw)\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "XYQAWZZ2rY75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = images.map(load_image)"
      ],
      "metadata": {
        "id": "D5dO2IRrtRng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.as_numpy_iterator().next()\n"
      ],
      "metadata": {
        "id": "t0rIw8qfr91G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_generator = images.batch(4).as_numpy_iterator()"
      ],
      "metadata": {
        "id": "Kpf6ISD-tcQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt_img = image_generator.next()"
      ],
      "metadata": {
        "id": "Q1I4XleuuHtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(ncols = 4, figsize=(20,20))\n",
        "for idx, image in enumerate(plt_img):\n",
        "  ax[idx].imshow(image)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "umG1IgmQu5bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Jj7tVcZQT__e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/My Drive\"\n"
      ],
      "metadata": {
        "id": "lrAZWrmPUOWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V3pmBk6hUSz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#moving matching labels:\n",
        "\n",
        "for folder in ['train', 'test', 'valid']:\n",
        "  for file in os.listdir(os.path.join('drive','MyDrive','data', folder, 'image')):\n",
        "    filename = file.split('.')[0]+'.json'\n",
        "    existing_filepath = os.path.join('drive','MyDrive','data', 'label', filename)\n",
        "    if os.path.exists(existing_filepath):\n",
        "      new_filepath = os.path.join('drive','MyDrive','data', folder, 'label', filename)\n",
        "      os.replace(existing_filepath, new_filepath)"
      ],
      "metadata": {
        "id": "Z2Yqw16kR6_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply Image Augmentation on Images and Labels"
      ],
      "metadata": {
        "id": "fkkgeDHTQYfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as alb"
      ],
      "metadata": {
        "id": "BnThR-dUAt9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Augmentation Pipeline:"
      ],
      "metadata": {
        "id": "EwNDexWIQjLO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(image):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "\n",
        "augmentor = alb.Compose([alb.HorizontalFlip(p=0.5),\n",
        "             alb.RandomBrightnessContrast(p=0.3),\n",
        "             alb.RandomCrop(width=700, height=700)],\n",
        "             bbox_params=alb.BboxParams(format='albumentations', label_fields = ['class_labels']))\n"
      ],
      "metadata": {
        "id": "K2-GzCx1RL3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test an Image & Annotation"
      ],
      "metadata": {
        "id": "v6i7_-pKTBlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(os.path.join('drive','MyDrive','data','train','image','27f557a6-850c-11ed-95e4-1e00f1349d90.jpg'))\n",
        "\n",
        "with open(os.path.join('drive','MyDrive','data','train','label','27f557a6-850c-11ed-95e4-1e00f1349d90.json'), 'r') as f:\n",
        "  label = json.load(f)\n"
      ],
      "metadata": {
        "id": "HNhR9EjHS8IS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(img)"
      ],
      "metadata": {
        "id": "UEKGo1h32ouL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img"
      ],
      "metadata": {
        "id": "RLSHSQdQR0KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filee = '27f557a6-850c-11ed-95e4-1e00f1349d90.jpg'\n",
        "new_file = (filee.split('.'))[0]\n",
        "new_file\n",
        "name = f'{new_file}.json'\n",
        "name"
      ],
      "metadata": {
        "id": "4JMO-km0XhrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label['shapes'][0]['points']"
      ],
      "metadata": {
        "id": "M9cCvVnwm4jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "take the coordinates as a list from the dict 'label'"
      ],
      "metadata": {
        "id": "O9pqcRk8nnyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coords = [0,0,0,0]\n",
        "coords[0] = label['shapes'][0]['points'][0][0]\n",
        "coords[1] = label['shapes'][0]['points'][0][1]\n",
        "coords[2] = label['shapes'][0]['points'][1][0]\n",
        "coords[3] = label['shapes'][0]['points'][1][1]"
      ],
      "metadata": {
        "id": "eVKYxwLLlqWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coords"
      ],
      "metadata": {
        "id": "9sxBZ0ClnkJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "normalize the coordinates by dividing x with width and y with height of the image"
      ],
      "metadata": {
        "id": "85EzND7VoBpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(img)"
      ],
      "metadata": {
        "id": "Mxz5LwfesWbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coords = list(np.divide( coords, [1280,720,1280,720]))"
      ],
      "metadata": {
        "id": "RKziO3F4n-Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coords"
      ],
      "metadata": {
        "id": "b7UrQbN8oUnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(coords)"
      ],
      "metadata": {
        "id": "-jRc-vgkrs74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "try augmentation pipeline"
      ],
      "metadata": {
        "id": "HmToGg6noe_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(img)"
      ],
      "metadata": {
        "id": "KxmoJEkRp3Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug = augmentor(image = img, bboxes=[coords], class_labels = ['face'])\n",
        "cv2.rectangle(aug['image'],\n",
        "              tuple(np.multiply(aug['bboxes'][0][:2], [700,700]).astype(int)),\n",
        "              tuple(np.multiply(aug['bboxes'][0][2:], [700,700]).astype(int)),\n",
        "              (0,255,0),2)"
      ],
      "metadata": {
        "id": "JOySNXNmof0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build an Augmentation Pipeline for all images"
      ],
      "metadata": {
        "id": "MRPR6gO9vLED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = []\n",
        "type(labels)"
      ],
      "metadata": {
        "id": "n_oShWvUIcmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filee = '27f557a6-850c-11ed-95e4-1e00f1349d90.jpg'\n",
        "new_file = (filee.split('.'))[0]\n",
        "new_file\n",
        "name = f'{new_file}.json'\n",
        "name"
      ],
      "metadata": {
        "id": "Qsktd7AbYkE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for folder in ['train', 'test', 'valid']:\n",
        "  for files in os.listdir(os.path.join('drive','MyDrive','data', folder, 'image')):\n",
        "    img = cv2.imread(os.path.join('drive','MyDrive','data', folder,'image', files))\n",
        "    label_path = os.path.join('drive','MyDrive','data', folder,'label', f'{(files.split(\".\"))[0]}.json')\n",
        "    coords = [0,0,0.000001,0.000001]\n",
        "    if os.path.exists(label_path):\n",
        "      with open(label_path, 'r') as f:\n",
        "        label = json.load(f)\n",
        "      coords[0] = label['shapes'][0]['points'][0][0]\n",
        "      coords[1] = label['shapes'][0]['points'][0][1]\n",
        "      coords[2] = label['shapes'][0]['points'][1][0]\n",
        "      coords[3] = label['shapes'][0]['points'][1][1]\n",
        "      coords = list(np.divide(coords, [1280, 720, 1280, 720]))\n",
        "\n",
        "    try:\n",
        "      for x in range(60):\n",
        "        augmented = augmentor(image = img, bboxes = [coords], class_labels = ['face'])\n",
        "        cv2.imwrite(os.path.join('drive','MyDrive','data','aug_data',folder,'image', f'{(files.split(\".\"))[0]}_{x}.jpg'), augmented['image'])\n",
        "        annotation = {}\n",
        "        annotation['image'] = files\n",
        "        if os.path.exists(label_path):\n",
        "          if len(augmented['bboxes']) == 0:\n",
        "            annotation['bbox'] = [0,0,0,0]\n",
        "            annotation['class'] = 0\n",
        "          else:\n",
        "            annotation['bbox'] = augmented['bboxes'][0]\n",
        "            annotation['class'] = 1\n",
        "        else:\n",
        "          annotation['bbox'] = [0,0,0,0]\n",
        "          annotation['class'] = 0\n",
        "\n",
        "        with open(os.path.join('drive','MyDrive','data','aug_data',folder,'label', f'{(files.split(\".\"))[0]}_{x}.json'), 'w') as f:\n",
        "          json.dump(annotation, f)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "5vlwqR_UtpKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a image resizing funtion for your images"
      ],
      "metadata": {
        "id": "sjTZawAk9QdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  def normalize_image(image):\n",
        "    return tf.image.resize(image, (120,120))\n"
      ],
      "metadata": {
        "id": "D2BrsG4lx2F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to read an image, decode it and reshape the tensor containing the pixel data:\n",
        "\n",
        "def load_image(x):\n",
        "  raw = tf.io.read_file(x)\n",
        "  img = tf.image.decode_jpeg(raw)\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "g8gDtASAhQ51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the files,\n",
        "#turn them into TensorSliceDataset\n",
        "#and normalize the image size and color::"
      ],
      "metadata": {
        "id": "LJzs_-iD9Vpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "try:\n",
        "  train_images = tf.data.Dataset.list_files(\"/content/drive/MyDrive/data/aug_data/train/image/*.jpg\", shuffle = False)\n",
        "  train_images = train_images.map(load_image)\n",
        "  train_images = train_images.map(normalize_image)\n",
        "  train_images = train_images.map(lambda x: x/255)\n",
        "\n",
        "except Exception as e :\n",
        "  print(e)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NrBtWXWDx2yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "  test_images = tf.data.Dataset.list_files(\"/content/drive/MyDrive/data/aug_data/test/image/*.jpg\", shuffle = False)\n",
        "  test_images = test_images.map(load_image)\n",
        "  test_images = test_images.map(normalize_image)\n",
        "  test_images = test_images.map(lambda x: x/255)\n",
        "\n",
        "except Exception as e :\n",
        "  print(e)\n",
        "\n"
      ],
      "metadata": {
        "id": "eeHYVCALCUUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "try:\n",
        "  valid_images = tf.data.Dataset.list_files(\"/content/drive/MyDrive/data/aug_data/valid/image/*.jpg\", shuffle = False)\n",
        "  valid_images = valid_images.map(load_image)\n",
        "  valid_images = valid_images.map(normalize_image)\n",
        "  valid_images = valid_images.map(lambda x: x/255)\n",
        "\n",
        "except Exception as e :\n",
        "  print(e)"
      ],
      "metadata": {
        "id": "p2jf4SQeGDII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_images),len(valid_images),len(test_images)"
      ],
      "metadata": {
        "id": "1LCjzb_QnvmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the labels, return the class and bboxes data :"
      ],
      "metadata": {
        "id": "jWS-X-D4K5p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def read_label(label_path):\n",
        "  with open(label_path.numpy(), 'r', encoding= 'utf-8') as f:\n",
        "    label = json.load(f)\n",
        "\n",
        "  return [label['class']], label['bbox']\n",
        ""
      ],
      "metadata": {
        "id": "WDofT3djK5Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "read_label(\"/content/drive/MyDrive/data/aug_data/train/label/27f557a6-850c-11ed-95e4-1e00f1349d90_0.json\")\n"
      ],
      "metadata": {
        "id": "uGsjsUmV1ne0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = tf.data.Dataset.list_files(\"/content/drive/MyDrive/data/aug_data/train/label/*.json\", shuffle = False)\n",
        "train_labels = train_labels.map(lambda x: tf.py_function(func = read_label, inp = [x], Tout = [tf.uint8, tf.float16]))\n",
        "\n",
        "valid_labels = tf.data.Dataset.list_files(\"/content/drive/MyDrive/data/aug_data/valid/label/*.json\", shuffle = False)\n",
        "valid_labels = valid_labels.map(lambda x: tf.py_function(func = read_label, inp = [x], Tout = [tf.uint8, tf.float16]))\n",
        "\n",
        "test_labels = tf.data.Dataset.list_files(\"/content/drive/MyDrive/data/aug_data/test/label/*.json\", shuffle = False)\n",
        "test_labels = test_labels.map(lambda x: tf.py_function(func = read_label, inp = [x], Tout = [tf.uint8, tf.float16]))\n"
      ],
      "metadata": {
        "id": "Sp6jpy674aaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "YvxJO4Zz5XMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_labels),len(valid_labels),len(test_labels)"
      ],
      "metadata": {
        "id": "ScRxNrSApX8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "COmbine Label and Image Samples"
      ],
      "metadata": {
        "id": "6V4hP4-wnZs6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = tf.data.Dataset.zip((train_images, train_labels))\n",
        "train = train.shuffle(4000)\n",
        "train = train.batch(8)\n",
        "train = train.prefetch(4)\n",
        "\n",
        "test = tf.data.Dataset.zip((test_images, test_labels))\n",
        "test = test.shuffle(900)\n",
        "test = test.batch(8)\n",
        "test = test.prefetch(4)\n",
        "\n",
        "valid = tf.data.Dataset.zip((valid_images, valid_labels))\n",
        "valid = valid.shuffle(800)\n",
        "valid = valid.batch(8)\n",
        "valid = valid.prefetch(4)"
      ],
      "metadata": {
        "id": "eRD4pNwE5dFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_samples = train.as_numpy_iterator()\n",
        "res = data_samples.next()\n",
        "\n",
        "fig, ax =plt.subplots(ncols = 4, figsize=(20,20))\n",
        "for idx in range(4):\n",
        "  sample_image = res[0][idx]\n",
        "  sample_coords = res[1][1][idx]\n",
        "\n",
        "  cv2.rectangle(sample_image,\n",
        "                tuple(np.multiply(sample_coords[:2], [120,120]).astype(int)),\n",
        "                tuple(np.multiply(sample_coords[2:],[120,120]).astype(int)),\n",
        "                (255,0,0),2)\n",
        "\n",
        "  ax[idx].imshow(sample_image)"
      ],
      "metadata": {
        "id": "4MkB909vu_Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build Deep Learning Model\n",
        "With the combination of both Classification and Regression"
      ],
      "metadata": {
        "id": "FzFEj86u2wx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
        "from tensorflow.keras.applications import VGG16"
      ],
      "metadata": {
        "id": "Wy5jD9SSzlWx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = VGG16(include_top = False)"
      ],
      "metadata": {
        "id": "PwdhIX9y3TxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our CNN"
      ],
      "metadata": {
        "id": "M6eppoSC8zOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "  input_layer = Input(shape=(120,120,3))\n",
        "  vgg = VGG16(include_top = False)(input_layer)\n",
        "\n",
        "  #Classification Model:\n",
        "  f1 = GlobalMaxPooling2D()(vgg)\n",
        "  class1 = Dense(2048, activation= 'relu')(f1)\n",
        "  class2 = Dense(1, activation = 'sigmoid')(class1)\n",
        "\n",
        "  #Regression Model:\n",
        "  f2 = GlobalMaxPooling2D()(vgg)\n",
        "  regress1 = Dense(2048, activation = 'relu')(f2)\n",
        "  regress2 = Dense(4, activation = 'sigmoid')(regress1)\n",
        "\n",
        "  facetracker = Model(inputs= input_layer, outputs = [class2, regress2])\n",
        "  return facetracker"
      ],
      "metadata": {
        "id": "OWdnPrcJ8yhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "facetracker = build_model()\n",
        "facetracker.summary()"
      ],
      "metadata": {
        "id": "XXZaSor63YYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.as_numpy_iterator().next()[1]"
      ],
      "metadata": {
        "id": "gmqz2w0UEFJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = train.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "bLacVbgvEl74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "Jp-5Nw_q_GFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "2A8-Wevj_TAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes, coords = facetracker.predict(X)"
      ],
      "metadata": {
        "id": "BX-HgHro_UoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes, coords"
      ],
      "metadata": {
        "id": "Q0qOcJe__bzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Lossesand Optimizers\n"
      ],
      "metadata": {
        "id": "y9FzSSUYFpYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "Batches_per_epoch = len(train)\n",
        "lr_decay = (1./0.75-1)/Batches_per_epoch\n",
        "opt = tf.keras.optimizers.Adam(learning_rate = 0.01,\n",
        "                                     decay = lr_decay)"
      ],
      "metadata": {
        "id": "9MFzhfyg_fEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Localization Loss:\n",
        "\n",
        "def loc_loss(y_true, yhat):\n",
        "  delta_coord = tf.reduce_sum(tf.square(y_true[:,:2]-yhat[:,:2]))\n",
        "\n",
        "  h_true = y_true[:,3] - y_true[:,1]\n",
        "  w_true = y_true[:,2] - y_true[:,0]\n",
        "\n",
        "  h_pred = yhat[:,3] - yhat[:,1]\n",
        "  w_pred = yhat[:,2] - yhat[:,0]\n",
        "\n",
        "  delta_size = tf.reduce_sum(tf.square(w_true-w_pred) + (h_true-h_pred))\n",
        "  return delta_coord + delta_size"
      ],
      "metadata": {
        "id": "qpgviN8tGXXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classloss = tf.keras.losses.BinaryCrossentropy()\n",
        "regressloss = loc_loss"
      ],
      "metadata": {
        "id": "UnsgUEreH2qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Neural Network"
      ],
      "metadata": {
        "id": "FMeFn2ZesFr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Facetracker(Model):\n",
        "  def __init__(self, eyetracker,  **kwargs):\n",
        "    super().__init__(**kwargs)\n",
        "    self.model = eyetracker\n",
        "  def compile(self, opt, classloss, regressloss, **kwargs):\n",
        "    super().compile(**kwargs)\n",
        "    self.closs = classloss\n",
        "    self.lloss = regressloss\n",
        "    self.opt = opt\n",
        "  def train_step(self, batch, **kwargs):\n",
        "    X, y = batch\n",
        "    with tf.GradientTape() as tape:\n",
        "      #Make predictions:\n",
        "      classes, coords = self.model(X, training = True)\n",
        "      #Calculate the loss:\n",
        "      batch_classloss = self.closs(y[0], classes)\n",
        "      batch_locloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
        "      total_loss = batch_classloss*0.5 + batch_locloss\n",
        "      #calculate the gradients:\n",
        "      grad = tape.gradient(total_loss, self.model.trainable_variables)\n",
        "      #loop through each variable:\n",
        "      opt.apply_gradients(zip(grad, self.model.trainable_variables))\n",
        "\n",
        "      return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_locloss}\n",
        "\n",
        "  def test_step(self, batch, **kwargs):\n",
        "    X, y = batch\n",
        "    classes, coords = self.model(X, training = False)\n",
        "    batch_classloss = self.closs(y[0], classes)\n",
        "    batch_locloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
        "    total_loss = batch_classloss*0.5 + batch_locloss\n",
        "    return {\"total_val_loss\":total_loss, \"val_class_loss\":batch_classloss, \"val_regress_loss\":batch_locloss}\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4eihK1VlrVT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Facetracker(facetracker)"
      ],
      "metadata": {
        "id": "pR0a_Doh5q2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(opt, classloss, loc_loss)"
      ],
      "metadata": {
        "id": "Fu6rz5Xt6DBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "dvRnoISO6e22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(train.take(100), epochs = 10, validation_data = valid)"
      ],
      "metadata": {
        "id": "-LHcLoQd6QYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist.history"
      ],
      "metadata": {
        "id": "TzS4Z9md6tIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(ncols=3, figsize=(20,5))\n",
        "\n",
        "ax[0].plot(hist.history['total_loss'], color='teal', label='loss')\n",
        "ax[0].plot(hist.history['val_total_val_loss'], color='orange', label='val loss')\n",
        "ax[0].title.set_text('Loss')\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].plot(hist.history['class_loss'], color='teal', label='class loss')\n",
        "ax[1].plot(hist.history['val_val_class_loss'], color='orange', label='val class loss')\n",
        "ax[1].title.set_text('Classification Loss')\n",
        "ax[1].legend()\n",
        "\n",
        "ax[2].plot(hist.history['regress_loss'], color='teal', label='regress loss')\n",
        "ax[2].plot(hist.history['val_val_regress_loss'], color='orange', label='val regress loss')\n",
        "ax[2].title.set_text('Regression Loss')\n",
        "ax[2].legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EGi1xJWSNuQk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}